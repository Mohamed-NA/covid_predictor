# COVID-19 Reinfection Prediction

A complete ML pipeline for predicting COVID-19 reinfection. Includes data cleaning, encoding, feature engineering, model training, evaluation, and deployment using FastAPI. The system accepts structured patient data and returns real-time predictions.

---

## üöÄ Project Overview

This project processes medical records to predict **Reinfection** cases using a trained classification model. It includes:
- Cleaned and preprocessed healthcare dataset.
- Feature engineering and standardization.
- A trained ML model for binary classification.
- FastAPI backend to expose the model for inference.
- React.js frontend for users to use the model.

---

## üß† Technologies Used

- Python
- FastAPI
- Next.js
- Pandas & NumPy
- Scikit-learn
- Pydantic
- Uvicorn
- Joblib

---

## üß™ How to Run the API

1. **Clone the repo:**

```bash
git clone https://github.com/your-username/covid_predictor
cd covid_predictor
```

2. **install dependencies:**

```bash
pip install -r requirements.txt
```

3. **Run the API:**

```bash
uvicorn ./main:app --reload
```

4. **Test the API:**

```bash
Go to http://127.0.0.1:8000/docs to use the interactive Swagger UI.
```

## üì• Example Request Body

```bash
[{
  "Age": 45,
  "Gender": "Male",
  "Region": "Hovedstaden",
  "Preexisting_Condition": "Diabetes",
  "Date_of_Infection": "2023-04-15",
  "COVID_Strain": "Omicron",
  "Symptoms": "Mild",
  "Severity": "Moderate",
  "Hospitalized": "Yes",
  "Hospital_Admission_Date": "2023-04-18",
  "Hospital_Discharge_Date": "2023-04-25",
  "ICU_Admission": "No",
  "Ventilator_Support": "No",
  "Recovered": "Yes",
  "Date_of_Recovery": "2023-05-10",
  "Reinfection": "No",
  "Date_of_Reinfection": "1900-01-01",  
  "Vaccination_Status": "Yes",
  "Vaccine_Type": "Pfizer",
  "Doses_Received": 2,
  "Date_of_Last_Dose": "2023-01-15",
  "Long_COVID_Symptoms": "Fatigue",  
  "Occupation": "Teacher",
  "Smoking_Status": "Former",
  "BMI": 25.3,
  "Recovery_Classification": "Fast Recovery"
}]
```

---

## ‚úÖ Expected Response Body

```bash
{
  "reinfection_prediction": "No",
  "description": "Non-Smoker, Normal BMI, No ICU history"
}
```

## Getting Started with the FrontEnd

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.js`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## üìÅ Project Structure

```bash
covid_predictor/
‚îú‚îÄ‚îÄ covid_predictor_api/
‚îÇ ‚îú‚îÄ‚îÄ main.py # FastAPI endpoint
‚îÇ ‚îú‚îÄ‚îÄ app/
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ model_interface.py # Loads the trained model and scaler
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py   # Feature engineering and transformation logic
‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py         # Input schema using Pydantic
‚îÇ ‚îî‚îÄ‚îÄ model/
‚îÇ     ‚îú‚îÄ‚îÄ encoders.pkl       # Saved LabelEncoders for categorical features
‚îÇ     ‚îú‚îÄ‚îÄ model.pkl          # Best Trained ML model (binary classifier)
‚îÇ     ‚îî‚îÄ‚îÄ scaler.pkl         # trained scaler used for scaling the input
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ splitted_data/
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ X_test.csv         # Test set features
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ X_train.csv        # Training set features
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ y_test.csv         # Test set labels
‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ y_train.csv        # Training set labels
‚îÇ ‚îú‚îÄ‚îÄ splitted_data_encoded/ 
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ X_test.csv         # Test set features with encoding
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ X_train.csv        # Training set features with encoding
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ y_test.csv         # Test set labels with encoding
‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ y_train.csv        # Training set labels with encoding
‚îÇ ‚îú‚îÄ‚îÄ covid1-19 Dataset.csv  # Data Used for training the model
‚îÇ ‚îî‚îÄ‚îÄ Cleaned_Data.csv       # Cleaned and preprocessed dataset
‚îÇ
‚îú‚îÄ‚îÄ frontend_next.js/
‚îÇ ‚îú‚îÄ‚îÄ app/
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ page.js            # Main page component
‚îÇ ‚îÇ   ‚îú‚îÄ‚îÄ components/        # Reusable React components
‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ styles/            # CSS/SCSS modules
‚îÇ ‚îú‚îÄ‚îÄ public/                # Static assets (images, icons, etc.)
‚îÇ ‚îú‚îÄ‚îÄ package.json           # Frontend dependencies and scripts
‚îÇ ‚îú‚îÄ‚îÄ next.config.js         # Next.js configuration
‚îÇ ‚îî‚îÄ‚îÄ README.md              # Frontend-specific documentation
‚îÇ
‚îú‚îÄ‚îÄ frontend_streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ pages/                  # Streamlit pages
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ COVID_Chatbot.py    # Streamlit chatbot interface
‚îÇ   ‚îî‚îÄ‚îÄ home.py                 # Main Streamlit application
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ ‚îú‚îÄ‚îÄ Data_Cleaning.ipynb       # Jupyter notebook for data cleaning
‚îÇ ‚îú‚îÄ‚îÄ Data_Splitting.ipynb      # Jupyter notebook for data splitting
‚îÇ ‚îú‚îÄ‚îÄ Encoding_Features.ipynb   # Jupyter notebook for encoding features
‚îÇ ‚îú‚îÄ‚îÄ EDA.ipynb                 # Exploratory Data Analysis notebook
‚îÇ ‚îú‚îÄ‚îÄ Model_Evaluation.ipynb    # Jupyter notebook for model evaluation
‚îÇ ‚îî‚îÄ‚îÄ Model_Training.ipynb      # Jupyter notebook for model training
‚îÇ
‚îú‚îÄ‚îÄ RagModule/
‚îÇ ‚îú‚îÄ‚îÄ data/                  # Data files for retrieval-augmented generation (RAG)
‚îÇ ‚îú‚îÄ‚îÄ scripts/               # Utility and pipeline scripts for RAG workflows
‚îÇ ‚îú‚îÄ‚îÄ tests/                 # Unit and integration tests for RAG components
‚îÇ ‚îú‚îÄ‚îÄ vector_store/          # Vector database files for document embeddings and retrieval
‚îÇ ‚îî‚îÄ‚îÄ README.md              # Documentation for the RAG module
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml           # Python project configuration 
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îÇ 
‚îú‚îÄ‚îÄ README.md                # Project documentation 
‚îÇ
‚îî‚îÄ‚îÄ uv.lock                   # Uvicorn lock file for FastAPI server
```

---

## Rag Module


### 1Ô∏è‚É£ Overview

This module implements a *Retrieval-Augmented Generation (RAG)* pipeline to provide evidence-based explanations for *COVID-19 reinfection risk*.
It uses:

* *FAISS* for vector search over PubMed abstracts.
* *HuggingFace sentence-transformers* for embeddings.
* *Google Generative AI (Gemini)* for LLM responses.

---

### 2Ô∏è‚É£ Environment Setup

```bash
# Create virtual environment
python -m venv CovidRag
source CovidRag/bin/activate   # Linux/Mac
CovidRag\Scripts\activate      # Windows

# Install dependencies
pip install -r requirements.txt
```

---

### 3Ô∏è‚É£ Environment Variables (.env)

```ini
GOOGLE_API_KEY=your_google_api_key
HUGGINGFACEHUB_API_TOKEN=your_hf_token
```

> Get HuggingFace token from: [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

---

### 4Ô∏è‚É£ Usage

*Step 1 ‚Äì Fetch PubMed abstracts*

```bash
python scripts/fetch_pubmed.py
```

*Step 2 ‚Äì Build FAISS vector store*

```bash
python scripts/build_vectorstore.py
```

*Step 3 ‚Äì Run RAG pipeline*

```bash
python scripts/rag_pipeline.py
```

---

### 5Ô∏è‚É£ Testing

```bash
# Test only retrieval
python test/test_retrieval.py

# Test full RAG flow
python test/test_rag_pipeline.py
```

---

### 6Ô∏è‚É£ Key Components

* *Embeddings Model*: sentence-transformers/all-MiniLM-L6-v2
* *LLM Model*: gemini-2.5-pro (Google Generative AI)
* *Retriever*: FAISS index over chunked PubMed abstracts
* *Prompt*: Medical assistant style, structured output

---

### 7Ô∏è‚É£ Prompt

![WhatsApp Image 2025-08-08 at 23 30 38](https://github.com/user-attachments/assets/4de6d1ee-8ffe-4f8c-b8f1-b663c460ef11)


## üôå Author
Mohamed Nasser
[LinkedIn](https://www.linkedin.com/in/mohamed-nasser-ahmed/) | [GitHub](https://github.com/Mohamed-NA)
